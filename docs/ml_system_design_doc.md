## hw_2
# Этапы решения задачи

### Этап 1. Подготовка данных

В данном разделе описаны источники данных, необходимые для обучения модели для предложений заявок, а также статус их доступности и качества.

#### 1.1. Таблица данных и сущностей

| Название данных / Сущность | Есть ли данные в компании (Источник) | Требуемый ресурс (Роли) | Проверено ли качество? (EDA) | Описание / Комментарий |
| :--- | :--- | :--- | :--- | :--- |
| **Целевая переменная**<br>(`deal_status` / `is_accepted`) | **Да**<br>`DEALS_HISTORY`<br>(Дамп таблицы заказов) | **Data Analyst / DS**<br>(SQL выгрузка) | **Частично (+/-)** | Таргет (Accepted/Rejected) присутствует. <br>**Проблема:** Выявлен дисбаланс классов (Accepted ~30%). Много записей в статусе `Pending` ("Цензурированные данные"), которые нужно либо исключить из обучения, либо использовать спец. методы (PU-learning). |
| **Текстовые признаки**<br>(`client_request`, `commercial_proposal`) | **Да**<br>`MESSAGES_LOG`<br>(Таблица переписки) | **Data Engineer**<br>(Настройка ETL для текстов) | **Да (+)** | Тексты полные, длина достаточная. <br>**Риск:** Возможны вкрапления HTML-тегов, смайликов (персональных данных: телефоны, имена), требующие очистки на препроцессинге. |
| **Финансовые признаки**<br>(`budget_est`) | **Да**<br>`DWH.DEAL_METADATA` | **Data Scientist**<br>(Написание Regex парсера) | **Нет (-)** | **Критическая проблема качества:** Поле "грязное". Содержит смесь валют (`$`), фиксированных сумм (`500`) и ставок (`0.10/word`). Напрямую использовать нельзя, требуется сложная логика очистки и приведения к единому знаменателю. |
| **Категориальные признаки**<br>(`sector`, `date`) | **Да**<br>`DEAL_METADATA` | **Data Analyst** | **Да (+)** | Сектора (Web, Design и др.) заполнены корректно без пропусков. Дата позволяет сгенерировать фичи сезонности (день недели, месяц). |
| **Внешние данные**<br>(Курсы валют / Инфляция) | **Нет** | **Data Engineer** | **Нет** | Возможно потребуется для нормализации бюджетов, если данные накоплены за несколько лет (сейчас не используется). |

#### 1.2. Описание процесса генерации данных
Данные поступают в систему нерегулярно (по факту создания заказа клиентом).
1.  **Event:** Пользователь заполняет форму на сайте -> создается запись в БД (PostgreSQL).
2.  **Lifecycle:** Фрилансер отправляет предложение -> обновляется таблица предложений.
3.  **Finalization:** Клиент нажимает "Принять" или "Отклонить" -> обновляется статус в таблице заказов (Таргет).
*Процесс выгрузки для обучения:* Еженедельный дамп новых завершенных сделок в `S3 Bucket` или `Feature Store`.

#### Если данных не достаточно, каковы способы решения этой проблемы, сколько данных еще нужно?
Основные стратегии решения данной проблемы:

* 1. Генерация и расширение данных
  * Data Augmentation (Аугментация): Создание новых примеров на основе имеющихся.

    * Для изображений: повороты, отражения, изменение яркости.

    * Для текста: замена слов синонимами, обратный перевод (Back-translation).

    * Синтетические данные: Использование алгоритмов (например, SMOTE для табличных данных) или нейросетей (GAN, VAE) для генерации похожих, но новых объектов.

 * 2. Использование готовых знаний
      *  Transfer Learning (Перенос обучения): Берется модель, уже обученная на огромном датасете (например, BERT для текста или ResNet для фото), и «дообучается» (fine-tuning) на ваших немногих данных.

      * Pre-trained Embeddings: Использование готовых векторных представлений слов (Word2Vec, FastText) вместо обучения своих.

#### 1.3. Конфиденциальность (Privacy)
Так как тексты заявок (`client_request`) могут содержать контакты и имена, перед передачей данных на обучение необходимо использовать **NER-маскирование** (замена сущностей на `<PERSON>`, `<PHONE>`).

#### 1.4. Краткое описание результата этапа (Выход)

Результатом этапа являются подготовленные витрины данных и зафиксированный обучающий датасет:

1.  **Обучающая выборка:** CSV/Parquet файл `training_dataset_v1.csv`, содержащий:
    *   Очищенные тексты (lowercased, without punctuation).
    *   Спаршенный численный бюджет (`budget_numeric`).
    *   Бинарный таргет (`target`: 1=Accepted, 0=Rejected).
    *   Метаданные (сектор, дата).
2.  **Пайплайн предобработки :** Скрипт `data_cleaning.py`, который умеет превращать "грязный" бюджет (строки типа "$0.10/word") в число.
3.  **Data Versioning:** Датасет зафиксирован в DVC (Data Version Control) для воспроизводимости экспериментов.

#### Структура обучающей выборки

Перед описанием этапов моделирования фиксируем структуру обучающей выборки.

**Описание данных и сущностей (Feature Store):**

| Тип данных | Название атрибута | Описание и источник | Обработка (Feature Engineering) |
| :--- | :--- | :--- | :--- |
| **Target** | `target_is_accepted` | Бинарный флаг (1/0). Получен из маппинга поля `status`.<br>Mapping: `Accepted` -> 1, `{Rejected, Pending, Negotiating}` -> 0. | **Важно:** `Pending` в MVP исключаем из train-set, так как судьба сделки неизвестна (Censored Data), либо размечаем отдельной моделью. |
| **Features (Text)** | `client_request` | Текст запроса клиента. | Clean -> Tokenize -> TF-IDF (Baseline) / Embeddings (MVP). |
| **Features (Text)** | `commercial_proposal` | Текст ответа исполнителя. | Выделение длины текста, наличия ключевых слов ("urgent", "guarantee"). Расчет `Similarity Score` между запросом и ответом. |
| **Features (Cat)** | `sector` | Отрасль (Web Dev, Design, etc). | One-Hot Encoding (OHE) или CatBoost Encoding. |
| **Features (Num)** | `budget_cleaned` | Очищенная сумма сделки. | Парсинг из `budget_est`. Для почасовых ставок (`/hour`, `/word`) применяется множитель (средняя длина проекта/текста из EDA), чтобы привести к Project Value. Log-transform для сглаживания "хвоста" дорогих заказов. |


### Этап 2. Подготовка прогнозных моделей
#### **1 . ML-метрики и функции потерь**
#### **Выбор типа задачи**

   * бинарная классификация — прогноз вероятности целевого события (например, успешная конверсия, дефолт, отклик);

   * Регрессия — прогноз числовой бизнес-метрики (цена квартиры, выручка и т.д.).

#### **1.2 Функция потерь**

LogLoss (Binary Cross-Entropy)
Используется как основная функция потерь, поскольку:

   * оптимизирует вероятностные предсказания;

   * штрафует за уверенные, но ошибочные прогнозы;

   * является стандартом для моделей градиентного бустинга и логистической регрессии.

#### **1.3 ML-метрики качества**

#### **1.3.1. Основные метрики:**

   * ROC-AUC — базовая метрика качества ранжирования, устойчива к дисбалансу классов;

   * PR-AUC — дополнительно используется при сильном дисбалансе;

   * Accuracy / F1-score — для интерпретации на фиксированном пороге;

   * LogLoss — для оценки калибровки вероятностей.

#### **1.3.2. Бизнес-метрики:**

   * uplift / прирост конверсии;

   * precision@k (качество топ-N решений);

   * ожидаемая прибыль / потери при использовании модели.

#### **Обоснование:**
   * ROC-AUC и LogLoss позволяют оптимизировать модель независимо от бизнес-порога, который может меняться со временем.

#### **2. Схема ML-валидации**
#### **Особенности данных:**

   * возможен временной порядок наблюдений;

   * наличие повторов сущностей (клиенты, сделки);

   * потенциальный target leakage.

#### **2.1 Выбранная схема валидации**

#### **Используется:**

   * Time-based split — если данные имеют временную природу;

   * либо Stratified K-Fold — при отсутствии явной временной зависимости и наличии дисбаланса классов.

#### **2.2 Обоснование**

   * предотвращение утечки будущей информации;

   * устойчивость оценки качества;

   * соответствие реальному сценарию использования модели.

#### **3. Структура бейзлайна**

   * Логистическая регрессия

   * минимальная предобработка;

   * one-hot encoding категорий, Label-hot encoding;

   * стандартизация числовых признаков.

#### **3.1 Цель:**

   * получить нижнюю границу качества;

   * проверить информативность признаков;

   * обеспечить интерпретируемую модель.

#### **3.2 Предобработка**

   * очистка пропусков (mean / median / mode);

   * базовая обработка категорий;

   * удаление явно утечек (leakage features).

#### **4. Процесс моделирования**

   * подготовка train/validation split(80/20);

   * обучение модели;

   * оценка ML-метрик;

   * сравнение с бейзлайном.

#### **4.1 Feature Engineering**

   * Кодирование категориальных переменных (One-Hot, Label Encoding).
   * Масштабирование числовых признаков (StandardScaler, MinMaxScaler).
   * Создание новых признаков (отношения, логарифмы, скользящие средние).
   * Удаление коррелирующих и нерелевантных признаков.

#### 4.2 **Оптимизация**

   * Bayesian Optimization / Optuna;

   * подбор порога классификации под бизнес-цель;

#### **4.3 Оптимизация гиперпараметров:**

   * Использование кросс валидации для подбора лушчих параметорв (GridSearch, RandomSearch)

#### **5. Анализ и интерпретация модели**

Здесь используются:

   * Feature Importance (gain / permutation);

   * SHAP values — локальная и глобальная интерпретация;

   * анализ ошибок по сегментам данных;

#### **5.1 Цель:**

   * объяснимость для бизнеса;

   * выявление неустойчивых и рискованных факторов;

   * контроль соответствия бизнес-логике.

#### 6. **Риски этапа и способы их снижения**

| Риск | Описание | Способы снижения |
|-----|----------|------------------|
| Target leakage | Использование признаков, прямо или косвенно содержащих информацию о таргете или будущем | Аудит признаков, строгая временная валидация, выполнение FE внутри фолдов |
| Переобучение модели | Высокое качество на train/CV и падение качества на новых данных | Кросс-валидация, early stopping, регуляризация, контроль разрыва train–val |
| Некорректная схема валидации | Попадание одних и тех же сущностей в train и val | GroupKFold / TimeSeriesSplit, проверка уникальности сущностей |
| Дисбаланс классов | Доминирование одного класса и искажение метрик качества | Использование ROC-AUC / PR-AUC, веса классов, стратифицированная CV |
| Нестабильность качества | Сильный разброс метрик между фолдами | Анализ дисперсии CV, упрощение модели, увеличение объёма данных |
| Ошибки предобработки | Разная логика обработки train и inference | Pipeline, единый код предобработки, тесты на воспроизводимость |
| Плохая интерпретируемость | Модель непонятна бизнесу или регулятору | SHAP, feature importance, использование интерпретируемых бейзлайнов |
| Data drift | Изменение распределений признаков во времени | Мониторинг признаков и метрик, регулярное переобучение |
| Ошибочный выбор метрики | Оптимизация ML-метрики не отражает бизнес-цель | Связка ML- и бизнес-метрик, валидация порогов |
| Ограничения по ресурсам | Долгое обучение или инференс | Ограничение сложности модели, отбор признаков, оптимизация инференса |

#### 7. **Необходимый результат этапа**

По итогам этапа должны быть получены:

   * обученный бейзлайн (или несколько);

   * подтверждённое качество на валидации;

   * выбранная ML-метрика и бизнес-метрика;

   * описание модели и интерпретации;

   * понимание ограничений и рисков;

   * готовность к переходу к MVP / пилоту / продакшену.


 ### Этапы, специфические для текущей задачи
**2.1. Baseline (Минимальное рабочее решение)**

*   **Гипотеза:** Простые ключевые слова (например, "Wordpress" + "дешево") и категория заказа дают базовое предсказание вероятности продажи.

*   **Входные данные:** `client_request` (склеенный с `commercial_proposal`), `sector`, `budget_cleaned`. У нас пока только 100 записей в датасете но далее добавим еще данные.
*   **Вход решения:**
    *   **Векторизация:** `TfidfVectorizer` (max_features=500, stop_words='english').
    *   **Модель:** Будем использовать логистическую Регрессию (`LogisticRegression` из sklearn) для нашего безлайна так как у нас не так много записей и она для таких задач подходит. 
*   **Ожидаемый результат:** Скрипт `train_baseline.py` и файл модели `logreg`. Метрика ROC-AUC > 0.60 / коэффицент детерминации (r2-score) > 0.60.

**2.2. MVP (Основное решение)**
*   **Гипотеза:** Успех сделки зависит от семантического соответствия (Semantic Match) ответа исполнителя запросу клиента, а также от адекватности цены рынку.
*   **Входные данные:** Раздельные тексты, явные признаки.
*   **Техника решения:**
    *   **Text Embedding:** Использование легковесного трансформера `all-MiniLM-L6-v2` для получения плотных векторов текстов Request и Proposal.
    *   **New Feature (Semantic Similarity):** Расчет косинусного расстояния между вектором Запроса и вектором Предложения. (Гипотеза: чем точнее ответ соответствует боли клиента, тем выше шанс).
    *   **Модель:** Градиентный бустинг (**CatBoostClassifier**). Он нативно работает с эмбеддингами и категориальными фичами (`sector`).
    *   **Валидация:** Stratified K-Fold (k=5), так как выборка мала (сотни примеров), кросс-валидация даст более устойчивую оценку.
*   **Ожидаемый результат:** Пайплайн обучения. ROC-AUC > 0.75. Сериализованный пайплайн.

### Этап 3. Интерпретация моделей (Validation & Interpretability)

*   **Техника:** Расчет **SHAP values** (SHapley Additive exPlanations)
*   **Вводные из EDA:** Мы знаем, что есть аномально дорогие заказы (>$5000), которые часто отклоняются.
*   **Что проверяем:**
    1.  Действительно ли рост `budget_cleaned` коррелирует со снижением вероятности покупки (или есть нелинейная зависимость)?
    2.  Какие слова в поле `commercial_proposal` имеют положительный вес (продающие триггеры)?
*   **Ожидаемый результат:** График Feature Importance и Summary Plot. Подтверждение от заказчика, что "логика модели не противоречит бизнесу".

### Этап 4. Интеграция бизнес-правил для метрик

*   **Бизнес-контекст:** Мы хотим максимизировать Revenue (выручку). Ложно-отрицательное предсказание для дорогого заказа (Model says "Reject", Client says "Accept") стоит нам дороже, чем ошибка на дешевом заказе.
*   **Метрика:** Взвешенный `Profit Score`:
    $$ \sum (TruePositive \times Budget \times Commission \%) - \sum (FalsePositive \times CostOfManagerTime) $$
*   **Ожидаемый результат:** Таблица сравнения Baseline vs MVP по потенциальной выручке.

### Этап 5. Подготовка инференса 
*   **Техника:** Оборачиваем модель MVP в REST API (FastAPI).
*   **Специфика данных:** API принимает JSON с полями `{text, sector, proposal, budget_str}`. Внутри сервиса должен "на лету" происходить тот же препроцессинг `budget_str` (очистка валют), что и на этапе обучения.
*   **Ожидаемый результат:** Docker-контейнер, отдающий прогноз за < 200ms.

### Этап 6. Интеграция бизнес-правил

*   **Правило "Safety Net":** Если сумма сделки > $3,000 (верхний квантиль по EDA), заявка **всегда** отправляется на ручную модерацию ("Human in the loop"), даже если модель предсказывает отказ. Риск потерять крупного клиента слишком велик.
*   **Правило "Low Confidence":** Если вероятность находится в "серой зоне" (0.4 – 0.6), ставить статус "Требует уточнения".
*   **Ожидаемый результат:** Реализация логического слоя (Policy Layer) поверх предикта модели.

### Этап 7. Подготовка финального отчета для бизнеса
*   **Состав отчета:**
    1.  Метрики на тестовой выборке (Baseline vs MVP).
    2.  Экономический расчет: сколько денег принесет внедрение модели (симуляция на исторических данных).
    3.  Примеры "Успешных" и "Провальных" кейсов.
*   **Ожидаемый результат:** Презентация и решение о деплое на prod.